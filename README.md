Digit Recognition Neural Network

Based on the NN in the Andrew Ng Course.

Fully vectorized over the examples. 

Stochastic Gradient Descent is lazy because it only chooses a random starting point for each batch of examples, instead of choosing every example at random.

Uses both basic gradient descent and an advanced gradient descent method from SciPy.
Need to change the advanced gradient descent parameters so it actually converges.

Still not getting great test results (maxing out at around 92% after playing with parameters). I'll probably add to this as I learn more and hopefully can improve it.